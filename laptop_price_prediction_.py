# -*- coding: utf-8 -*-
"""Laptop price prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N6hnbI3wif32SLd5k0Df0DZG_J4URCzp
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('/content/laptop_price - dataset.csv')

data

data.columns

data.info()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.base import BaseEstimator, TransformerMixin
import joblib

# Custom Transformer for NLP-based Categorical Encoding
class TextVectorizer(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.vectorizers = {}

    def fit(self, X, y=None):
        for column in X.columns:
            vectorizer = TfidfVectorizer()
            self.vectorizers[column] = vectorizer.fit(X[column].astype(str))
        return self

    def transform(self, X):
        transformed_columns = []
        for column in X.columns:
            transformed = self.vectorizers[column].transform(X[column].astype(str))
            transformed_columns.append(transformed.toarray())
        return np.hstack(transformed_columns)

# Load the dataset
df = pd.read_csv("/content/laptop_price - dataset.csv")  # Replace with your file path

# Preprocessing
X = df.drop(columns=["Price (Euro)"])
y = df["Price (Euro)"]

# Identify categorical and numerical columns
categorical_cols = ["Company", "Product", "TypeName", "ScreenResolution", "CPU_Company", "CPU_Type", "Memory", "GPU_Company", "GPU_Type", "OpSys"]
numerical_cols = ["Inches", "CPU_Frequency (GHz)", "RAM (GB)", "Weight (kg)"]

# Define the preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numerical_cols),  # Standard scaling for numerical features
        ("cat", TextVectorizer(), categorical_cols),  # NLP-based encoding for categorical features
    ]
)

# Define the model pipeline
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", RandomForestRegressor(n_estimators=100, random_state=42))
])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model
model.fit(X_train, y_train)

# Save the model and preprocessor
joblib.dump(model, "laptop_price_model_nlp.pkl")

# Evaluate the model
y_pred = model.predict(X_test)
print("R^2 Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
import joblib

# Load the dataset
df = pd.read_csv("/content/laptop_price - dataset.csv")  # Replace with your dataset path

# Preprocessing
X = df.drop(columns=["Price (Euro)"])
y = df["Price (Euro)"]

# Identify categorical, text-based, and numerical columns
categorical_cols = ["Company", "TypeName", "CPU_Company", "GPU_Company", "OpSys"]
text_cols = ["ScreenResolution", "Product", "CPU_Type", "Memory", "GPU_Type"]
numerical_cols = ["Inches", "CPU_Frequency (GHz)", "RAM (GB)", "Weight (kg)"]

# Define individual transformers
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown="ignore")
text_transformer = TfidfVectorizer()

# Define the preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numerical_transformer, numerical_cols),  # Scale numerical features
        ("cat", categorical_transformer, categorical_cols),  # Encode categorical features
        # Apply TfidfVectorizer individually to each text column
        ("text_screen_resolution", TfidfVectorizer(), "ScreenResolution"),
        ("text_product", TfidfVectorizer(), "Product"),
        ("text_cpu_type", TfidfVectorizer(), "CPU_Type"),
        ("text_memory", TfidfVectorizer(), "Memory"),
        ("text_gpu_type", TfidfVectorizer(), "GPU_Type"),
    ]
)

# Define the model pipeline
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", RandomForestRegressor(n_estimators=100, random_state=42))
])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model
model.fit(X_train, y_train)

# Save the model
joblib.dump(model, "laptop_price_model_nlp2.pkl")

# Evaluate the model
y_pred = model.predict(X_test)
print("R^2 Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

data.columns

data['Product'].unique()

data['TypeName'].unique()

data['ScreenResolution'].unique()

data['CPU_Company'].unique()

data['CPU_Type'].unique()

data['Memory'].unique()

data['GPU_Company'].unique()

data['GPU_Type'].unique()

data['OpSys'].unique()

data['Inches'].unique()

data['CPU_Frequency (GHz)'].unique()

data['RAM (GB)'].unique()

data['Weight (kg)'].unique()

data['Price (Euro)'].unique()